{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session4 Iteration4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chaitra257/EIP-images/blob/master/Session4_Iteration4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ei8iWszGdfbp",
        "colab_type": "text"
      },
      "source": [
        "In iteration 4, the changes planned are \n",
        "* Add Learning rate scheduler\n",
        "* Change batch size\n",
        "\n",
        "Result expected: Increase in accuracy from 99.28 to around 99.4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlo9gRVJFzZU",
        "colab_type": "code",
        "outputId": "b12b830c-6c7e-4d87-fcec-cf77479dd9ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNyZv-Ec52ot",
        "colab_type": "text"
      },
      "source": [
        "# **Import Libraries and modules**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m3w1Cw49Zkt",
        "colab_type": "code",
        "outputId": "db6f8c03-7708-4004-ea7f-93ac66a48802",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Install and import keras\n",
        "# https://keras.io/\n",
        "#!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eso6UHE080D4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import numpy for mathematical operations, and other required functions, dataset\n",
        "# from keras to build the model\n",
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zByEi95J86RD",
        "colab_type": "text"
      },
      "source": [
        "### Load pre-shuffled MNIST data into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eRM0QWN83PV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the shuffled data into train and test \n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a4Be72j8-ZC",
        "colab_type": "code",
        "outputId": "624b1874-1489-4fed-fa25-aa40d0be7f97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "source": [
        "# View a sample train image\n",
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa201afe7f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkmprriw9AnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reshape the model according to keras structure\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2m4YS4E9CRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Scale the numbers to change the range from 0-255 to 0-1\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mn0vAYD9DvB",
        "colab_type": "code",
        "outputId": "939b4439-95ff-48e8-c057-8cf6a8b49db1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Check the first 10 numbers\n",
        "y_train[:10]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG8JiXR39FHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYlFRvKS9HMB",
        "colab_type": "code",
        "outputId": "93558f33-ac60-4b6d-fea2-f5c069a77023",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "# Check the same 10 numbers as arrays now\n",
        "Y_train[:10]\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GdI18eQo-ubv"
      },
      "source": [
        "Observations and results:\n",
        "\n",
        "Iteration 2\n",
        "1. Added 3 BN layers (after each block) # parameters - 16.3k. Model was mainly around 98.8-99.2. 16th epoch hit 99.32\n",
        "2. Change 3rd Conv layer kernel size (from 16 to 10) # parameters - 12.8k. Model accuracy around 98.9-99.2 18th epoch hit 99.32\n",
        "3.  Change 3rd Conv layer kernel size (from 16 to 12) # parameters - 13.9k. Model accuracy around 98.9-99.2 16th epoch hit 99.28\n",
        "4. Added BN after each Conv Layer # parameters - 14.1k. Model accuracy around 99.0-99.2 20th epoch hit 99.29\n",
        "5. Added bottle neck block.(Conv layer with 12 kernel after MP) # parameters - 13.9k. Model accuracy around 98.9-99.1 15th epoch hit 99.13\n",
        "6. Removed the 1x1 layer after the first MP and kept the next conv layer with 12 kernels.  # parameters - 14.1k. Model accuracy around 98.9-99.2 20th epoch hit 99.18\n",
        "7. (Reverting to step 2)Changed the Conv Layer after the first MP to have 10 kernels instead of 12.  # parameters - 12.8k. Model accuracy around 99.0-99.2 17th epoch hit 99.29\n",
        "\n",
        "Iteration 3\n",
        "8. Added DO after each Conv Layer # parameters - 12.9k. Model accuracy around 99.0-99.2 15th epoch hit 99.35\n",
        "9. Added an extra Conv layer after MP (adjusted kernels to 8 and 16) # parameters - 14.6k. Model accuracy around 99.1-99.3 18th epoch hit 99.41\n",
        "\n",
        "Iteration4\n",
        "10. Implemented Learning Rate Scheduler. **# parameters - 14.6k. Model accuracy around 99.2-99.4 10th epoch hit 99.52**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osKqT73Q9JJB",
        "colab_type": "code",
        "outputId": "7aaf8293-4a45-4cc3-fbe7-ee72bc7ccf1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        }
      },
      "source": [
        "#Instantiate the Sequential model\n",
        "from keras.layers import Activation, MaxPooling2D, BatchNormalization, Dropout\n",
        "model = Sequential()\n",
        "\n",
        " \n",
        "model.add(Convolution2D(16, 3, 3, activation='relu', input_shape=(28,28,1))) #26\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu')) #24\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) #12\n",
        "#model.add(Convolution2D(12, 1, 1, activation='relu')) #12\n",
        "\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu')) #10\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) #8\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu')) #6\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) #3\n",
        "\n",
        "\n",
        "model.add(Convolution2D(10, 1, activation='relu')) #3\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(10, 3))\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0708 13:53:46.024368 140335020689280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \"\"\"\n",
            "W0708 13:53:46.041140 140335020689280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0708 13:53:46.044462 140335020689280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0708 13:53:46.090873 140335020689280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0708 13:53:46.092159 140335020689280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0708 13:53:46.686928 140335020689280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0708 13:53:46.775314 140335020689280 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
            "  \n",
            "W0708 13:53:47.018804 140335020689280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzdAYg1k9K7Z",
        "colab_type": "code",
        "outputId": "97c7eb43-8183-4d06-ce54-06522ce6eb6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 936
        }
      },
      "source": [
        "# Check the model summary to see which layers connect to which layer and what output each layer would give\n",
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 26, 26, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 32)        4640      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 24, 24, 32)        128       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 10, 10, 8)         2312      \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 10, 10, 8)         32        \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 10, 10, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 8, 8, 16)          1168      \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 8, 8, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 6, 6, 32)          4640      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 6, 6, 32)          128       \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 6, 6, 32)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 3, 3, 10)          330       \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 3, 3, 10)          40        \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 3, 3, 10)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 1, 1, 10)          910       \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 14,616\n",
            "Trainable params: 14,388\n",
            "Non-trainable params: 228\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp6SuGrL9M3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile the model\n",
        "from keras.optimizers import Nadam, Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "# model.compile(loss='categorical_crossentropy',\n",
        "#              optimizer=Nadam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004),\n",
        "#              metrics=['accuracy'])\n",
        "filepath = '/content/gdrive/My Drive/4_Iter4.hdf5'\n",
        "checkpoint= ModelCheckpoint(filepath, save_weights_only=False, save_best_only=True, monitor='val_acc', mode='max', verbose=1, period=1)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer = Adam(lr=0.03), metrics =['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xWoKhPY9Of5",
        "colab_type": "code",
        "outputId": "1429ae5d-b94e-451c-fbf5-e96dafc3371e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Fit the model with the given parameters for the current dataset\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=32, epochs=20, \n",
        "          callbacks=[LearningRateScheduler(scheduler, verbose=1), checkpoint], \n",
        "                     validation_data=(X_test, Y_test),verbose=1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0708 13:57:17.484425 140335020689280 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "60000/60000 [==============================] - 39s 658us/step - loss: 0.1676 - acc: 0.9475 - val_loss: 0.0488 - val_acc: 0.9850\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.98500, saving model to /content/gdrive/My Drive/4_Iter4.hdf5\n",
            "Epoch 2/20\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "60000/60000 [==============================] - 37s 616us/step - loss: 0.0647 - acc: 0.9798 - val_loss: 0.0423 - val_acc: 0.9864\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.98500 to 0.98640, saving model to /content/gdrive/My Drive/4_Iter4.hdf5\n",
            "Epoch 3/20\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "60000/60000 [==============================] - 37s 618us/step - loss: 0.0510 - acc: 0.9842 - val_loss: 0.0269 - val_acc: 0.9911\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.98640 to 0.99110, saving model to /content/gdrive/My Drive/4_Iter4.hdf5\n",
            "Epoch 4/20\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "60000/60000 [==============================] - 37s 618us/step - loss: 0.0437 - acc: 0.9860 - val_loss: 0.0299 - val_acc: 0.9902\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.99110\n",
            "Epoch 5/20\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "60000/60000 [==============================] - 37s 619us/step - loss: 0.0391 - acc: 0.9878 - val_loss: 0.0264 - val_acc: 0.9913\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.99110 to 0.99130, saving model to /content/gdrive/My Drive/4_Iter4.hdf5\n",
            "Epoch 6/20\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "60000/60000 [==============================] - 37s 617us/step - loss: 0.0345 - acc: 0.9887 - val_loss: 0.0237 - val_acc: 0.9921\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.99130 to 0.99210, saving model to /content/gdrive/My Drive/4_Iter4.hdf5\n",
            "Epoch 7/20\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "60000/60000 [==============================] - 37s 620us/step - loss: 0.0325 - acc: 0.9898 - val_loss: 0.0178 - val_acc: 0.9934\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.99210 to 0.99340, saving model to /content/gdrive/My Drive/4_Iter4.hdf5\n",
            "Epoch 8/20\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "60000/60000 [==============================] - 37s 615us/step - loss: 0.0298 - acc: 0.9905 - val_loss: 0.0217 - val_acc: 0.9928\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.99340\n",
            "Epoch 9/20\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "60000/60000 [==============================] - 37s 619us/step - loss: 0.0283 - acc: 0.9910 - val_loss: 0.0194 - val_acc: 0.9944\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.99340 to 0.99440, saving model to /content/gdrive/My Drive/4_Iter4.hdf5\n",
            "Epoch 10/20\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "60000/60000 [==============================] - 37s 617us/step - loss: 0.0262 - acc: 0.9917 - val_loss: 0.0177 - val_acc: 0.9952\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.99440 to 0.99520, saving model to /content/gdrive/My Drive/4_Iter4.hdf5\n",
            "Epoch 11/20\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "60000/60000 [==============================] - 37s 619us/step - loss: 0.0242 - acc: 0.9922 - val_loss: 0.0193 - val_acc: 0.9949\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.99520\n",
            "Epoch 12/20\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "60000/60000 [==============================] - 37s 613us/step - loss: 0.0239 - acc: 0.9923 - val_loss: 0.0204 - val_acc: 0.9944\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.99520\n",
            "Epoch 13/20\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "60000/60000 [==============================] - 37s 623us/step - loss: 0.0229 - acc: 0.9925 - val_loss: 0.0209 - val_acc: 0.9933\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.99520\n",
            "Epoch 14/20\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "60000/60000 [==============================] - 37s 621us/step - loss: 0.0229 - acc: 0.9930 - val_loss: 0.0195 - val_acc: 0.9936\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.99520\n",
            "Epoch 15/20\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "60000/60000 [==============================] - 37s 618us/step - loss: 0.0218 - acc: 0.9933 - val_loss: 0.0198 - val_acc: 0.9938\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.99520\n",
            "Epoch 16/20\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "60000/60000 [==============================] - 37s 619us/step - loss: 0.0200 - acc: 0.9934 - val_loss: 0.0188 - val_acc: 0.9946\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.99520\n",
            "Epoch 17/20\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "60000/60000 [==============================] - 37s 618us/step - loss: 0.0205 - acc: 0.9932 - val_loss: 0.0188 - val_acc: 0.9942\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.99520\n",
            "Epoch 18/20\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "60000/60000 [==============================] - 37s 622us/step - loss: 0.0188 - acc: 0.9939 - val_loss: 0.0175 - val_acc: 0.9943\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.99520\n",
            "Epoch 19/20\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "60000/60000 [==============================] - 37s 620us/step - loss: 0.0190 - acc: 0.9938 - val_loss: 0.0194 - val_acc: 0.9946\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.99520\n",
            "Epoch 20/20\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "60000/60000 [==============================] - 37s 618us/step - loss: 0.0186 - acc: 0.9938 - val_loss: 0.0194 - val_acc: 0.9936\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.99520\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa1f0f195c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtsH-lLk-eLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check the score to assess the performance of the model against test data\n",
        "model.load_weights('/content/gdrive/My Drive/4_Iter4.hdf5')\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkX8JMv79q9r",
        "colab_type": "code",
        "outputId": "30b16431-1ed3-49fc-8ebb-188d5b9adda5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Print the calculated score\n",
        "print(score)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.017727949214505496, 0.9952]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCWoJkwE9suh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use the model to predict on the test data\n",
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym7iCFBm9uBs",
        "colab_type": "code",
        "outputId": "b3c79288-36f8-467c-e42f-792722d67549",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        }
      },
      "source": [
        "# Compare predicted values and test data values\n",
        "print(y_pred[:9])\n",
        "print(y_test[:9])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.31361401e-21 3.35524743e-15 5.00384998e-13 6.07876283e-09\n",
            "  7.02483097e-23 8.68361078e-16 1.32729399e-37 1.00000000e+00\n",
            "  1.86888225e-13 1.06379385e-08]\n",
            " [6.52158449e-13 1.40973663e-15 1.00000000e+00 9.53943146e-19\n",
            "  8.15206182e-29 1.26542336e-19 5.22294256e-11 1.11373489e-23\n",
            "  4.14521119e-14 7.99364633e-16]\n",
            " [2.62824528e-12 9.99994874e-01 8.31321003e-08 2.06339665e-13\n",
            "  4.11549900e-06 1.13241583e-09 2.08777551e-09 5.13807038e-07\n",
            "  3.01763123e-07 1.57050359e-10]\n",
            " [1.00000000e+00 4.81469316e-19 1.04837701e-11 1.68617674e-17\n",
            "  5.64163275e-18 2.45464981e-14 2.35043895e-09 2.15893770e-09\n",
            "  6.07411121e-14 1.74545296e-12]\n",
            " [1.20226575e-15 2.42105467e-18 1.93440726e-16 1.35914801e-15\n",
            "  1.00000000e+00 6.60563885e-16 2.00584409e-13 3.16007531e-09\n",
            "  2.09754297e-11 1.17553105e-08]\n",
            " [1.74970756e-13 9.99946117e-01 3.10965559e-10 8.52996059e-15\n",
            "  4.82001542e-06 1.47626323e-12 3.28850174e-13 4.89803278e-05\n",
            "  1.16659102e-07 8.06474165e-10]\n",
            " [3.92979615e-20 8.33845915e-16 1.13922061e-09 4.98023940e-17\n",
            "  9.99975920e-01 2.88155999e-10 1.59348564e-19 2.40725839e-09\n",
            "  2.32841594e-05 8.35997184e-07]\n",
            " [2.22411097e-23 1.77383730e-09 3.21271829e-11 3.89829445e-12\n",
            "  6.54650330e-06 9.31105471e-11 6.59991704e-23 5.02372016e-12\n",
            "  2.10286726e-05 9.99972463e-01]\n",
            " [8.72637726e-12 8.23540223e-29 6.59334236e-22 6.30034372e-15\n",
            "  1.88106345e-15 2.24293634e-01 7.75700450e-01 2.45526103e-22\n",
            "  5.91704929e-06 1.89314744e-14]]\n",
            "[7 2 1 0 4 1 4 9 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT--y98_dr2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a dictionary of layers and their names\n",
        "layer_dict = dict([(layer.name, layer) for layer in model.layers])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GY4Upv4dsUR",
        "colab_type": "code",
        "outputId": "660a337c-f009-400e-dfd8-05d3257570b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 741
        }
      },
      "source": [
        "# Visualize the kernel\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from keras import backend as K\n",
        "%matplotlib inline\n",
        "# util function to convert a tensor into a valid image\n",
        "def deprocess_image(x):\n",
        "    # normalize tensor: center on 0., ensure std is 0.1\n",
        "    x -= x.mean()\n",
        "    x /= (x.std() + 1e-5)\n",
        "    x *= 0.1\n",
        "\n",
        "    # clip to [0, 1]\n",
        "    x += 0.5\n",
        "    x = np.clip(x, 0, 1)\n",
        "\n",
        "    # convert to RGB array\n",
        "    x *= 255\n",
        "    #x = x.transpose((1, 2, 0))\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x\n",
        "\n",
        "def vis_img_in_filter(img = np.array(X_train[2]).reshape((1, 28, 28, 1)).astype(np.float64), \n",
        "                      layer_name = 'conv2d_25'):\n",
        "    layer_output = layer_dict[layer_name].output\n",
        "    img_ascs = list()\n",
        "    for filter_index in range(layer_output.shape[3]):\n",
        "        # build a loss function that maximizes the activation\n",
        "        # of the nth filter of the layer considered\n",
        "        loss = K.mean(layer_output[:, :, :, filter_index])\n",
        "\n",
        "        # compute the gradient of the input picture wrt this loss\n",
        "        grads = K.gradients(loss, model.input)[0]\n",
        "\n",
        "        # normalization trick: we normalize the gradient\n",
        "        grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
        "\n",
        "        # this function returns the loss and grads given the input picture\n",
        "        iterate = K.function([model.input], [loss, grads])\n",
        "\n",
        "        # step size for gradient ascent\n",
        "        step = 5.\n",
        "\n",
        "        img_asc = np.array(img)\n",
        "        # run gradient ascent for 20 steps\n",
        "        for i in range(20):\n",
        "            loss_value, grads_value = iterate([img_asc])\n",
        "            img_asc += grads_value * step\n",
        "\n",
        "        img_asc = img_asc[0]\n",
        "        img_ascs.append(deprocess_image(img_asc).reshape((28, 28)))\n",
        "        \n",
        "    if layer_output.shape[3] >= 35:\n",
        "        plot_x, plot_y = 6, 6\n",
        "    elif layer_output.shape[3] >= 23:\n",
        "        plot_x, plot_y = 4, 6\n",
        "    elif layer_output.shape[3] >= 11:\n",
        "        plot_x, plot_y = 2, 6\n",
        "    else:\n",
        "        plot_x, plot_y = 1, 2\n",
        "    fig, ax = plt.subplots(plot_x, plot_y, figsize = (12, 12))\n",
        "    ax[0, 0].imshow(img.reshape((28, 28)), cmap = 'gray')\n",
        "    ax[0, 0].set_title('Input image')\n",
        "    fig.suptitle('Input image and %s filters' % (layer_name,))\n",
        "    fig.tight_layout(pad = 0.3, rect = [0, 0, 0.9, 0.9])\n",
        "    for (x, y) in [(i, j) for i in range(plot_x) for j in range(plot_y)]:\n",
        "        if x == 0 and y == 0:\n",
        "            continue\n",
        "        ax[x, y].imshow(img_ascs[x * plot_y + y - 1], cmap = 'gray')\n",
        "        ax[x, y].set_title('filter %d' % (x * plot_y + y - 1))\n",
        "\n",
        "vis_img_in_filter()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAwoAAALUCAYAAACre8XKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x864 with 12 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tvptcn8dxvp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}